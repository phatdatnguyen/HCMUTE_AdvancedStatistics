{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb56f953-8dfb-42f2-9ff0-eea0e5a2f9d6",
   "metadata": {},
   "source": [
    "# **Chapter 2. Fundamentals of Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57e89d-9143-4e53-8e70-2e19f8945d35",
   "metadata": {},
   "source": [
    "## **2.3. Probability Distributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1c182-d903-408e-b925-85adf3bc14bf",
   "metadata": {},
   "source": [
    "Probability distributions describe how values of a random variable are distributed. Common distributions include:\n",
    "\n",
    "1. **Uniform Distribution:** All outcomes are equally likely.\n",
    "2. **Normal Distribution:** Data is symmetrically distributed around the mean (bell-shaped curve).\n",
    "3. **Binomial Distribution:** Models the number of successes in a sequence of independent trials.\n",
    "4. **Poisson Distribution:** Models the number of events in a fixed interval of time or space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db97d06-eb3f-4202-bfee-d96add027211",
   "metadata": {},
   "source": [
    "### **2.3.1. Uniform distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3d89b-440a-4388-a424-c6e686e96b5e",
   "metadata": {},
   "source": [
    "The **uniform distribution** is the simplest probability distribution, where all outcomes within a specific range \\([a, b]\\) are equally likely. \n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{cases} \n",
    "\\frac{1}{b-a}, & a \\leq x \\leq b \\\\ \n",
    "0, & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Use Cases:**\n",
    "- Modeling scenarios where all outcomes have equal likelihood, such as rolling a fair die or drawing random numbers in a fixed range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2127-d89e-41e9-9900-1c3465deea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Generate data for a uniform distribution\n",
    "a, b = 0, 1  # Define range [a, b]\n",
    "x = np.linspace(a, b, 100)\n",
    "y = uniform.pdf(x, loc=a, scale=b-a)\n",
    "\n",
    "# Plot the uniform distribution\n",
    "plt.plot(x, y, label='Uniform PDF')\n",
    "plt.fill_between(x, y, alpha=0.2, color='blue')\n",
    "plt.title('Uniform Distribution (PDF)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = uniform.rvs(loc=a, scale=b-a, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917bbce-2648-44a9-adf8-8dbdea639568",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 1</b></p>\n",
    "\n",
    "1. Generate 1,000 random numbers from a uniform distribution over the interval $[0, 5]$:\n",
    "   - Compute the sample mean and variance.\n",
    "   - Verify that the theoretical mean and variance match the sample values.\n",
    "\n",
    "2. Plot the probability density function (PDF) of a uniform distribution over $[10, 20]$. Overlay a histogram of 500 samples from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552962e9-ad1d-49b0-b8ae-cf2ff11142a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a5cdc-d8de-48a7-bc77-e4a2f3d172e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e112066-1570-4a41-9c9a-7bc0cfb3de88",
   "metadata": {},
   "source": [
    "### **2.3.2. Normal Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1150fcc-72fa-45b8-81cb-00e41b06d477",
   "metadata": {},
   "source": [
    "The **normal distribution** (or **Gaussian distribution**) is the most commonly used probability distribution. It is defined by its mean ($\\mu$) and standard deviation ($\\sigma$).\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "**Properties:**\n",
    "- Bell-shaped curve, symmetric about the mean ($\\mu$).\n",
    "- Approximately 68% of data falls within 1 standard deviation ($\\sigma$) from the mean, 95% within 2, and 99.7% within 3 (empirical rule).\n",
    "\n",
    "**Use Cases:**\n",
    "- Modeling natural phenomena like heights, weights, test scores, and measurement errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1b1e-ae65-4057-bd91-c6c1d0f7119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters for the normal distribution\n",
    "mean, std_dev = 0, 1\n",
    "\n",
    "# Generate data for normal distribution\n",
    "x = np.linspace(-4, 4, 100)\n",
    "y = norm.pdf(x, loc=mean, scale=std_dev)\n",
    "\n",
    "# Plot the normal distribution\n",
    "plt.plot(x, y, label='Normal PDF')\n",
    "plt.fill_between(x, y, alpha=0.2, color='green')\n",
    "plt.title('Normal Distribution (PDF)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = norm.rvs(loc=mean, scale=std_dev, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900bcae-d510-466a-8653-bd91156524b5",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 2</b></p>\n",
    "\n",
    "1. Generate 1,000 random numbers from a normal distribution with a mean of 50 and a standard deviation of 5:\n",
    "   - Compute the sample mean and standard deviation.\n",
    "   - Compare these values with the theoretical mean and standard deviation.\n",
    "\n",
    "2. Plot the probability density function (PDF) of a normal distribution with $\\mu = 0$ and $\\sigma = 2$. Overlay a histogram of 1,000 samples drawn from the same distribution.\n",
    "\n",
    "3. Create a cumulative distribution function (CDF) plot for a standard normal distribution. Highlight the region corresponding to values within 1 standard deviation of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17cb36-59e4-4ca5-8aa0-b1d7a3dadb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a467d6-a29b-4c09-8788-2f3cbc06bdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3cde3-9eef-4765-b245-42125942a9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c890c7d7-2c6c-4925-9548-6de36e9ec7f1",
   "metadata": {},
   "source": [
    "### **2.3.3. Student's t-Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36134a-5938-4d24-b62d-237c0b6fab89",
   "metadata": {},
   "source": [
    "The **Student's t-distribution** (or simply **t-distribution**) is a probability distribution that is used to estimate population parameters when the sample size is small and/or the population variance is unknown. It is defined by its degrees of freedom (df).\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "$$\n",
    "f(x) = \\frac{\\Gamma\\left( \\frac{df + 1}{2} \\right)}{\\sqrt{df\\pi} \\, \\Gamma\\left( \\frac{df}{2} \\right)} \\left( 1 + \\frac{x^2}{df} \\right)^{-\\frac{df + 1}{2}}\n",
    "$$\n",
    "where $\\Gamma$ is the gamma function.\n",
    "\n",
    "$$\n",
    "\\Gamma(n) = \\int_0^\\infty t^{n-1} e^{-t} \\, dt \\quad (n > 0)\n",
    "$$\n",
    "\n",
    "**Properties:**\n",
    "- Symmetrical and bell-shaped, similar to the normal distribution, but with heavier tails.\n",
    "- As degrees of freedom increase, the t-distribution approaches the normal distribution.\n",
    "- The shape of the t-distribution depends on the degrees of freedom (df): with lower df, the distribution has heavier tails.\n",
    "\n",
    "**Use Cases:**\n",
    "- Often used in hypothesis testing (e.g., t-tests) when the sample size is small.\n",
    "- Useful for estimating confidence intervals for the mean of a normally distributed population when the sample size is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be2012-b398-46de-82e3-b66e934c696d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the Student's t-distribution\n",
    "df = 5  # degrees of freedom\n",
    "\n",
    "# Generate data for t-distribution\n",
    "x = np.linspace(-4, 4, 100)\n",
    "y = t.pdf(x, df)\n",
    "\n",
    "# Plot the t-distribution\n",
    "plt.plot(x, y, label=f'Student\\'s t-distribution (df={df})')\n",
    "plt.fill_between(x, y, alpha=0.2, color='blue')\n",
    "plt.title('Student\\'s t-Distribution (PDF)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = t.rvs(df, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Standard Deviation: {np.std(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ee868-bfeb-4785-879b-4b1de3be0174",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 3</b></p>\n",
    "\n",
    "1. Generate 1,000 random numbers from a Student's t-distribution with 10 degrees of freedom:\n",
    "   - Compute the sample mean and standard deviation.\n",
    "   - Compare these values with the theoretical mean and standard deviation (which are 0 and $\\sqrt{\\frac{df}{df-2}}$ for df > 2).\n",
    "\n",
    "2. Plot the probability density function (PDF) of a Student's t-distribution with 3 degrees of freedom. Overlay a histogram of 1,000 samples drawn from the same distribution.\n",
    "\n",
    "3. Create a cumulative distribution function (CDF) plot for a Student's t-distribution with 5 degrees of freedom. Highlight the region corresponding to values within 1 standard deviation of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac9666-38a6-46f5-9298-62828a70d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49185d78-daf0-4a65-97da-ae4c4f8f8d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2aa6b9-ee6d-457f-b6da-cfde274c67c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0273e601-968a-46e3-9089-e1ee6d624412",
   "metadata": {},
   "source": [
    "### **2.3.4. F Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c1d0b-b65a-4c90-bea9-ef50ec0f7328",
   "metadata": {},
   "source": [
    "The **F Distribution** is a probability distribution that arises frequently in the context of statistical inference, particularly in the analysis of variance (ANOVA) and regression analysis. It describes the ratio of two scaled chi-squared distributions and is defined by two sets of degrees of freedom: $\\text{df}_1$ (numerator degrees of freedom) and $\\text{df}_2$ (denominator degrees of freedom).\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "$$\n",
    "f(x; \\text{df}_1, \\text{df}_2) = \\frac{\\left(\\frac{\\text{df}_1}{\\text{df}_2}\\right)^{\\frac{\\text{df}_1}{2}} \\frac{x^{\\frac{\\text{df}_1}{2}-1}}{(1+\\frac{\\text{df}_1}{\\text{df}_2} x)^{\\frac{\\text{df}_1+\\text{df}_2}{2}}}}{\\text{B}\\left(\\frac{\\text{df}_1}{2}, \\frac{\\text{df}_2}{2}\\right)} \\quad \\text{for } x \\geq 0\n",
    "$$\n",
    "where $\\text{B}$ is the beta function.\n",
    "\n",
    "**Properties:**\n",
    "- The F distribution is right-skewed, especially for smaller degrees of freedom, and approaches a normal distribution as degrees of freedom increase.\n",
    "- The mean of the F distribution is given by $\\frac{\\text{df}_1}{\\text{df}_1 - 2}$ for $\\text{df}_1 > 2$, and the variance is $\\frac{2 \\cdot \\text{df}_1^2(\\text{df}_2 + 1)}{\\text{df}_2(\\text{df}_1 - 2)^2 (\\text{df}_1 - 4)}$ for $\\text{df}_1 > 4$.\n",
    "\n",
    "**Use Cases:**\n",
    "- Commonly used in ANOVA tests to compare variances among groups.\n",
    "- Essential in regression analysis to compare the fits of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e78f-4bfb-4292-ab4d-33f0430d01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the F distribution\n",
    "df1 = 5  # degrees of freedom numerator\n",
    "df2 = 2  # degrees of freedom denominator\n",
    "\n",
    "# Generate data for F distribution\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = f.pdf(x, df1, df2)\n",
    "\n",
    "# Plot the F distribution\n",
    "plt.plot(x, y, label=f'F Distribution (df1={df1}, df2={df2})')\n",
    "plt.fill_between(x, y, alpha=0.2, color='purple')\n",
    "plt.title('F Distribution (PDF)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.xlim(0, 5)\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = f.rvs(df1, df2, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e97bd3-f168-4bc2-899d-a7f582ced519",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 4</b></p>\n",
    "\n",
    "1. Generate 1,000 random numbers from an F distribution with 10 and 5 degrees of freedom respectively for the numerator and the denominator:\n",
    "   - Compute the sample mean and variance.\n",
    "   - Compare these values with the theoretical mean (\\(\\frac{df_1}{df_1 - 2}\\) for \\(df_1 > 2\\)) and variance.\n",
    "\n",
    "2. Plot the probability density function (PDF) of an F distribution with 3 and 2 degrees of freedom. Overlay a histogram of 1,000 samples drawn from the same distribution.\n",
    "\n",
    "3. Create a cumulative distribution function (CDF) plot for an F distribution with 5 and 10 degrees of freedom. Highlight the region corresponding to values within 1 standard deviation of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c57a5-2a46-417d-bed7-36311d15ae7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19f964-09c0-4b53-b1ea-a82c1ba28bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770449bc-168e-401e-af37-1e8b7b2c9440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0069b14-0b50-4e9c-8671-d75e736c249f",
   "metadata": {},
   "source": [
    "### **2.3.5. Chi-Squared Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b6e09-b1d8-400d-8e4c-b5fbc4646853",
   "metadata": {},
   "source": [
    "The **Chi-Squared distribution** is a probability distribution that is commonly used in hypothesis testing, particularly in tests of independence and goodness-of-fit. It is defined by its degrees of freedom (df) and is used in scenarios where we are dealing with the sum of the squares of independent standard normal random variables.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "$$\n",
    "f(x; df) = \\frac{1}{2^{df/2} \\Gamma\\left(\\frac{df}{2}\\right)} x^{\\frac{df}{2}-1} e^{-\\frac{x}{2}} \\quad \\text{for } x \\geq 0\n",
    "$$\n",
    "\n",
    "**Properties:**\n",
    "- The Chi-Squared distribution is non-negative and right-skewed, especially for low degrees of freedom.\n",
    "- As degrees of freedom increase, the distribution approaches a normal distribution.\n",
    "- The mean of the Chi-Squared distribution is equal to its degrees of freedom (\\(df\\)), and the variance is equal to \\(2 \\times df\\).\n",
    "\n",
    "**Use Cases:**\n",
    "- Widely used in statistical tests (e.g., Chi-Squared tests for independence, goodness-of-fit tests).\n",
    "- Useful in the construction of confidence intervals for variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d025a4-1c47-49ce-aed0-36a82db5d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the Chi-Squared distribution\n",
    "df = 5  # degrees of freedom\n",
    "\n",
    "# Generate data for Chi-Squared distribution\n",
    "x = np.linspace(0, 20, 100)\n",
    "y = chi2.pdf(x, df)\n",
    "\n",
    "# Plot the Chi-Squared distribution\n",
    "plt.plot(x, y, label=f'Chi-Squared Distribution (df={df})')\n",
    "plt.fill_between(x, y, alpha=0.2, color='orange')\n",
    "plt.title('Chi-Squared Distribution (PDF)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.xlim(0, 20)\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = chi2.rvs(df, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5f3ee-d91d-41c0-aa47-49c07394b629",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 5</b></p>\n",
    "\n",
    "1. Generate 1,000 random numbers from a Chi-Squared distribution with 10 degrees of freedom:\n",
    "   - Compute the sample mean and variance.\n",
    "   - Compare these values with the theoretical mean (df) and variance (2 * df).\n",
    "\n",
    "2. Plot the probability density function (PDF) of a Chi-Squared distribution with 3 degrees of freedom. Overlay a histogram of 1,000 samples drawn from the same distribution.\n",
    "\n",
    "3. Create a cumulative distribution function (CDF) plot for a Chi-Squared distribution with 5 degrees of freedom. Highlight the region corresponding to values within one standard deviation from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1064944-98ec-4782-b3d7-aab611506a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc56ed-2e11-403d-a1fa-f23ac592c9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1426b-5d52-4bc0-bcd9-012067dd1c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64eb42b-5dea-4897-8fa4-a831e0c2d5df",
   "metadata": {},
   "source": [
    "### **2.3.6. Binomial Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a88e7e-42ef-4a21-8db2-faef993a167e",
   "metadata": {},
   "source": [
    "The **binomial distribution** models the number of successes in \\(n\\) independent trials, where each trial has two possible outcomes (success or failure).\n",
    "\n",
    "**Probability Mass Function (PMF):**\n",
    "$$\n",
    "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\(n\\): Number of trials.\n",
    "- \\(p\\): Probability of success.\n",
    "- \\(k\\): Number of successes.\n",
    "\n",
    "**Properties:**\n",
    "- Discrete distribution.\n",
    "- The mean is $np$ and the variance is $np(1-p)$.\n",
    "\n",
    "**Use Cases:**\n",
    "- Modeling pass/fail scenarios like flipping a coin, quality control, or survey results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeed87-01fd-493d-933b-e2717a230516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# Parameters for the binomial distribution\n",
    "n, p = 10, 0.5  # Number of trials, probability of success\n",
    "\n",
    "# Generate data for binomial distribution\n",
    "x = np.arange(0, n+1)\n",
    "y = binom.pmf(x, n, p)\n",
    "\n",
    "# Plot the binomial distribution\n",
    "plt.bar(x, y, label='Binomial PMF', color='purple', alpha=0.7)\n",
    "plt.title('Binomial Distribution (PMF)')\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = binom.rvs(n, p, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f0192-40cd-4f40-9a90-3d98ad32cbc2",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 6</b></p>\n",
    "\n",
    "1. A die is rolled 10 times. Assuming a success is rolling a 6:\n",
    "   - Plot the probability mass function (PMF) for the number of successes.\n",
    "   - Compute the probability of rolling exactly 3 sixes.\n",
    "\n",
    "2. Simulate 1,000 trials of flipping a coin 20 times, where $p=0.4$ (probability of heads). Compute the mean and variance of the sample and compare them to the theoretical values.\n",
    "\n",
    "3. Write a function that computes the cumulative probability of at least $k$ successes in $n$ trials, given $p$. Test it for $n=15$, $p=0.3$, and $k=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40359fd3-42c8-4020-8be9-3700f70f92a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0609c-d04e-4f48-84f1-68b819e7d95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f2b0a-b4ae-4a7b-bf76-a188821c37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68667a2-0891-4110-8130-426159d8d426",
   "metadata": {},
   "source": [
    "### **2.3.7. Poisson Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f839-8648-4232-b523-3c3a0544fa16",
   "metadata": {},
   "source": [
    "The **Poisson distribution** models the number of events occurring in a fixed interval of time or space, given a known average rate ($\\lambda$) and independence of events.\n",
    "\n",
    "**Probability Mass Function (PMF):**\n",
    "$$\n",
    "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $k$: Number of events.\n",
    "- $\\lambda$: Average rate of occurrence.\n",
    "\n",
    "**Properties:**\n",
    "- Discrete distribution.\n",
    "- The mean and variance are both equal to $\\lambda$.\n",
    "\n",
    "**Use Cases:**\n",
    "- Modeling rare events like the number of calls at a call center, traffic accidents, or radioactive decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943465dd-c879-45d1-b1c3-cdccda0e9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "# Parameter for the Poisson distribution\n",
    "lambda_ = 4  # Average rate of occurrence\n",
    "\n",
    "# Generate data for Poisson distribution\n",
    "x = np.arange(0, 15)\n",
    "y = poisson.pmf(x, lambda_)\n",
    "\n",
    "# Plot the Poisson distribution\n",
    "plt.bar(x, y, label='Poisson PMF', color='orange', alpha=0.7)\n",
    "plt.title('Poisson Distribution (PMF)')\n",
    "plt.xlabel('Number of Events')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Random sampling\n",
    "samples = poisson.rvs(lambda_, size=1000)\n",
    "print(f\"Sample Mean: {np.mean(samples)}, Sample Variance: {np.var(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d9997-c7da-4a62-a3c4-ca2dc339380a",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 7</b></p>\n",
    "\n",
    "1. A call center receives an average of 4 calls per hour. Assuming calls follow a Poisson process:\n",
    "   - Plot the PMF for the number of calls received in an hour.\n",
    "   - Compute the probability of receiving exactly 5 calls in an hour.\n",
    "   - Compute the probability of receiving more than 7 calls in an hour.\n",
    "\n",
    "2. Simulate 1,000 random samples from a Poisson distribution with $\\lambda = 3$:\n",
    "   - Compute the mean and variance of the sample.\n",
    "   - Compare these values to the theoretical mean and variance.\n",
    "\n",
    "3. Generate 100 random Poisson-distributed data points with $\\lambda = 5$. Create a histogram and overlay it with the theoretical PMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2801a42-680d-4ed4-8d9e-18cacf1156b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f00d4-2d4e-4a0f-96b5-ee946d61de31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a6a81-6fc2-4921-a28a-a31d1b445691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c359d3-9a91-41ed-baca-4067f420d35d",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 8</b></p>\n",
    "\n",
    "**Task 1: Load the Dataset**\n",
    "1. Load the Iris dataset (`IrisFlower.csv`) into a Pandas DataFrame.\n",
    "2. Display the first 10 rows of the dataset to understand its structure.\n",
    "\n",
    "**Task 2: Descriptive Statistics**\n",
    "1. Compute the mean, median, variance, and standard deviation for the `sepal length` feature for the entire dataset.\n",
    "2. Group the data by species and compute the mean and variance of all numeric features for each species.\n",
    "\n",
    "**Task 3: Probability Distributions**\n",
    "1. Plot the histogram and probability density function (PDF) for the `sepal length` feature.\n",
    "2. Compute the skewness and kurtosis for the `sepal length` feature.\n",
    "\n",
    "**Task 4: Data Visualization**\n",
    "1. Create a box plot to compare the `sepal length` distribution across species.\n",
    "2. Create a scatter plot of `sepal length` vs. `petal length`, coloring points by species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d5f71-c390-4e7b-b22c-b1ba286c4f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68b4f9-89b9-4340-b7c9-27169886834a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5b8d4-c0f6-4ff5-9790-867f28390b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718acba-3581-41d6-b678-13fcda2e0e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "344096ac-7d52-4a00-8780-f7fee4c303b2",
   "metadata": {},
   "source": [
    "## **2.4. Inferential Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20def3-283d-4f03-a9bd-cba4429ef216",
   "metadata": {},
   "source": [
    "Inferential statistics involves drawing conclusions about a population based on a sample. Key concepts include:\n",
    "\n",
    "1. **Confidence Intervals**: Estimating the range within which a population parameter lies.\n",
    "2. **Hypothesis Testing**: Testing assumptions or claims about a population using sample data.\n",
    "3. **p-values**: Measuring the strength of evidence against the null hypothesis.\n",
    "\n",
    "In this section, we will explore these concepts with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9dde2-2a61-4347-b465-bf19b4afb133",
   "metadata": {},
   "source": [
    "### **2.4.1. Confidence Intervals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa30476-d02e-4b07-bdb4-0362322bcf59",
   "metadata": {},
   "source": [
    "A **confidence interval (CI)** is a range of values that is likely to contain a population parameter (e.g., mean) with a specified level of confidence.\n",
    "\n",
    "**Formula for CI of the Mean:**\n",
    "$$\n",
    "CI = \\bar{x} \\pm Z \\cdot \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{x}$: Sample mean\n",
    "- $Z$: Z-critical value for the desired confidence level (e.g., 1.96 for 95%)\n",
    "- $s$: Sample standard deviation\n",
    "- $n$: Sample size\n",
    "\n",
    "**Interpretation:**\n",
    "- A 95% confidence interval means that if we repeated the sampling process multiple times, 95% of the calculated intervals would contain the true population mean.\n",
    "\n",
    "**Use Cases:**\n",
    "- Estimating population parameters (e.g., mean, proportion).\n",
    "- Assessing the precision of sample estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e86f7e-bedc-4eb0-b06d-d3034a848669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Example: Confidence Interval for the Mean\n",
    "data = [15, 18, 22, 20, 18, 30, 28, 22, 18]  # Sample data\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)\n",
    "n = len(data)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Compute the margin of error\n",
    "z_critical = norm.ppf((1 + confidence_level) / 2)  # Z-critical value for 95% confidence\n",
    "margin_of_error = z_critical * (sample_std / np.sqrt(n))\n",
    "\n",
    "# Confidence interval\n",
    "lower_bound = sample_mean - margin_of_error\n",
    "upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"95% Confidence Interval: [{lower_bound}, {upper_bound}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd18b87-0d11-444f-b26b-8a278a0f6238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "x = np.linspace(sample_mean - 3 * sample_std, sample_mean + 3 * sample_std, 1000)\n",
    "y = norm.pdf(x, loc=sample_mean, scale=sample_std / np.sqrt(n))\n",
    "\n",
    "plt.plot(x, y, label=\"Sampling Distribution\")\n",
    "plt.axvline(sample_mean, color='blue', linestyle='--', label=\"Sample Mean\")\n",
    "plt.axvline(lower_bound, color='red', linestyle='--', label=\"Lower Bound (95% CI)\")\n",
    "plt.axvline(upper_bound, color='red', linestyle='--', label=\"Upper Bound (95% CI)\")\n",
    "plt.fill_between(x, y, where=(x >= lower_bound) & (x <= upper_bound), color='red', alpha=0.2, label=\"95% CI Region\")\n",
    "plt.title(\"Confidence Interval Visualization\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e03de8-18e1-4fd5-b8fa-6e41ac2bee37",
   "metadata": {},
   "source": [
    "### **2.4.2. Statistical Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f43b7f-729c-4f21-afba-e7ba3542b2cb",
   "metadata": {},
   "source": [
    "**Statistical hypothesis testing** is a method used to make inferences or draw conclusions about a population based on sample data. It involves evaluating two competing hypotheses: the null hypothesis and the alternative hypothesis.\n",
    "\n",
    "**Key Components:**\n",
    "1. **Null Hypothesis ($H_0$)**: The statement being tested, usually positing that there is no effect or no difference. It serves as the default assumption.\n",
    "\n",
    "2. **Alternative Hypothesis ($H_1$ or $H_a$)**: The statement that is accepted if the null hypothesis is rejected. It represents a new effect or difference, suggesting that there is something happening in the population.\n",
    "\n",
    "3. **Significance Level ($\\alpha$)**: The probability of rejecting the null hypothesis when it is actually true, commonly set at values like 0.05 (5%) or 0.01 (1%).\n",
    "\n",
    "4. **Test Statistic**: A standardized value derived from sample data that is used to determine whether to reject the null hypothesis. The choice of test statistic depends on the hypothesis test being conducted.\n",
    "\n",
    "5. **P-Value**: The probability of observing the test statistic, or something more extreme, given that the null hypothesis is true. A low p-value (typically less than $\\alpha$) indicates strong evidence against the null hypothesis.\n",
    "\n",
    "6. **Decision Rule**: A systematic method to decide whether to reject the null hypothesis based on the comparison of the p-value with the significance level. If the p-value is less than $\\alpha$, you reject $H_0$.\n",
    "\n",
    "**Steps in Hypothesis Testing:**\n",
    "1. **State the Hypotheses**: Clearly articulate the null and alternative hypotheses.\n",
    "2. **Choose a Significance Level**: Decide on the threshold for rejecting the null hypothesis.\n",
    "3. **Collect Data**: Gather and prepare the data required for the test.\n",
    "4. **Calculate the Test Statistic and P-Value**: Determine the test statistic from the sample data and compute the corresponding p-value.\n",
    "5. **Make a Decision**: Compare the p-value with the significance level and decide whether to reject or fail to reject the null hypothesis.\n",
    "6. **Draw Conclusions**: Interpret the results in the context of the research question.\n",
    "\n",
    "**Considerations:**\n",
    "- Type I Error: The error made when the null hypothesis is rejected when it is true (false positive).\n",
    "- Type II Error: The error made when the null hypothesis is not rejected when it is false (false negative).\n",
    "- Power of the Test: The probability of correctly rejecting the null hypothesis when it is false. Higher power indicates a greater ability to detect an effect.\n",
    "\n",
    "Statistical hypothesis testing is a critical tool in inferential statistics, providing a formal framework for making decisions based on data. Understanding the principles of hypothesis testing is essential for analyzing data and interpreting results in various fields, including science, business, and social sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01d33a-c8c2-4db4-a207-8f6b69b7d66d",
   "metadata": {},
   "source": [
    "### **2.4.3. t-Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80545a-ff6b-484a-ac42-ddcc8cd16b98",
   "metadata": {},
   "source": [
    "The **t-test** is used to determine whether there is a significant difference between the means of one or two groups.\n",
    "\n",
    "**Assumptions:**\n",
    "- Data is approximately normally distributed.\n",
    "- Variances of the groups are equal (can be relaxed for Welch's t-test).\n",
    "\n",
    "**Use Cases:**\n",
    "- Comparing the effectiveness of treatments.\n",
    "- Testing claims about population means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc38ac9-90fa-4e6d-bec9-8ca146695983",
   "metadata": {},
   "source": [
    "#### ***2.4.3.1. One-Sample t-Test***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d12f44-9e5b-402c-a92a-f0c69603da9c",
   "metadata": {},
   "source": [
    "Tests whether the mean of a sample is significantly different from a hypothesized population mean.\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu_0}{\\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{x}$: Sample mean\n",
    "- $\\mu_0$: Hypothesized population mean\n",
    "- $s$: Sample standard deviation\n",
    "- $n$: Sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dffe1-0c85-4fb1-bba0-00763b6b16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Example: One-Sample t-Test\n",
    "# Null Hypothesis (H0): The mean of the sample is equal to a hypothesized value (e.g., 20)\n",
    "hypothesized_mean = 20\n",
    "t_stat, p_value = ttest_1samp(data, popmean=hypothesized_mean)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is significantly different from the hypothesized mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between the sample mean and the hypothesized mean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d291f9-259f-4425-8830-45316a875acb",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 9</b></p>\n",
    "\n",
    "**Exercise:** One-Sample t-Test\n",
    "\n",
    "1. **Data Collection**: Suppose you have collected the following sample data representing the weights (in kg) of a group of individuals:\n",
    "\n",
    "   ```python\n",
    "   data = [65, 70, 75, 80, 60, 58, 90, 77, 85, 68]\n",
    "   ```\n",
    "\n",
    "2. **Hypothesize**: Your research question is to determine if the average weight of this group is significantly different from a known population mean weight of 70 kg.\n",
    "\n",
    "3. **Perform the One-Sample t-Test**:\n",
    "   - State the null hypothesis (\\(H_0\\)) and alternative hypothesis (\\(H_a\\)).\n",
    "   - Use the One-Sample t-Test to test the hypothesis, calculating the t-statistic and p-value.\n",
    "   - Choose a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the results of the t-test and the chosen significance level, conclude whether to reject or fail to reject the null hypothesis.\n",
    "   - What does this imply about the average weight of your sample compared to the population mean?\n",
    "\n",
    "5. **Bonus Question**: If you repeat the test with a significance level of 0.01, how does your conclusion change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4359ab-a372-412a-bfe7-9faa0c528d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9b9ed-b2e9-448b-b73c-34d9766d7a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254f121-14f5-4448-8e2f-be9580fe0d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3e77d-4ec8-4372-9ca8-b98af95bb3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e9098-72bb-4942-bdf9-3dcad0503809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfe7cf5a-5e31-4a41-b164-2e71fbec84cb",
   "metadata": {},
   "source": [
    "#### ***2.4.3.2. Two-Sample t-Test***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fed7b8-2561-4d9b-8ea5-f44b9a781d2e",
   "metadata": {},
   "source": [
    "Tests whether the means of two independent samples are significantly different.\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{x}_1, \\bar{x}_2$: Sample means\n",
    "- $s_1^2, s_2^2$: Sample variances\n",
    "- $n_1, n_2$: Sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a42ee-ef58-40a1-92ef-84d7903f3bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Example: Two-Sample t-Test\n",
    "# Sample data for two groups\n",
    "group1 = [15, 18, 22, 20, 18]\n",
    "group2 = [30, 28, 25, 27, 22]\n",
    "\n",
    "# Null Hypothesis (H0): The means of the two groups are equal\n",
    "t_stat, p_value = ttest_ind(group1, group2)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The means of the two groups are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between the means of the two groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3412d-380c-483a-a008-efd0409ec0ee",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 10</b></p>\n",
    "\n",
    "**Exercise:** Two-Sample t-Test\n",
    "\n",
    "1. **Data Collection**: You have conducted an experiment to compare the effects of two different treatments on blood pressure reduction. The following data shows the reduction in systolic blood pressure (in mmHg) for each group:\n",
    "\n",
    "   - **Treatment Group 1**:\n",
    "   ```python\n",
    "   group1 = [8, 6, 7, 5, 9]\n",
    "   ```\n",
    "\n",
    "   - **Treatment Group 2**:\n",
    "   ```python\n",
    "   group2 = [12, 14, 13, 11, 15]\n",
    "   ```\n",
    "\n",
    "2. **Hypothesize**: Your research question is to determine if there is a significant difference in the mean blood pressure reduction between the two treatment groups.\n",
    "\n",
    "3. **Perform the Two-Sample t-Test**:\n",
    "   - State the null hypothesis (\\(H_0\\)) and alternative hypothesis (\\(H_a\\)).\n",
    "   - Use the Two-Sample t-Test to test the hypothesis, calculating the t-statistic and p-value.\n",
    "   - Choose a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the results of the t-test and the chosen significance level, conclude whether to reject or fail to reject the null hypothesis.\n",
    "   - What does this imply about the effectiveness of the two treatments concerning blood pressure reduction?\n",
    "\n",
    "5. **Bonus Question**: If you were to collect additional data that lowers the variance within the treatment groups, how might that affect your results? Discuss the implications of sample size and variance on the hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c065bf7-e480-4097-8ea9-8402423c6c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e793-fb7e-45b1-b338-623fbaa515f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ebab4-b64b-4f34-9f08-7a913014bdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24f917-098a-4017-b2e3-712961573083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b292dfe5-7cc6-4728-ac4b-316171ef96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbf5f5e-05ff-4d8a-8e2d-d95a2adbb870",
   "metadata": {},
   "source": [
    "### **2.4.4. F-Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b91c3-1451-482b-b051-ea1c89011241",
   "metadata": {},
   "source": [
    "The **F-Test** is a statistical test used to determine whether there are significant differences between the variances of two populations. It is often used in the context of ANOVA (Analysis of Variance) to compare multiple group variances, but it can also be used to compare the variances of two independent samples.\n",
    "\n",
    "**Test Statistic:**\n",
    "$$\n",
    "F = \\frac{s_1^2}{s_2^2}\n",
    "$$\n",
    "Where:\n",
    "- $s_1^2$: Sample variance of the first group\n",
    "- $s_2^2$: Sample variance of the second group\n",
    "\n",
    "**Key Components:**\n",
    "1. **Null Hypothesis ($H_0$)**: The null hypothesis states that the variances of the two populations are equal ($\\sigma_1^2 = \\sigma_2^2$).\n",
    "\n",
    "2. **Alternative Hypothesis ($H_a$)**: The alternative hypothesis posits that the variances are not equal ($\\sigma_1^2 \\neq \\sigma_2^2$).\n",
    "\n",
    "3. **Degrees of Freedom**:\n",
    "   - For the numerator: $df_1 = n_1 - 1$, where $n_1$ is the sample size of group 1.\n",
    "   - For the denominator: $df_2 = n_2 - 1$, where $_2$ is the sample size of group 2.\n",
    "\n",
    "4. **Significance Level ($\\alpha$)**: The threshold used to decide whether to reject the null hypothesis. Common choices for $\\alpha$ are 0.05 or 0.01.\n",
    "\n",
    "**Steps in F-Test:**\n",
    "1. **State the Hypotheses**: Clearly articulate the null and alternative hypotheses.\n",
    "2. **Calculate the Sample Variances**: Compute the variances for the two samples.\n",
    "3. **Calculate the F-Statistic**: Use the F formula to calculate the test statistic.\n",
    "4. **Determine the Critical Value**: Find the critical value from the F-distribution table based on the degrees of freedom and chosen significance level.\n",
    "5. **Make a Decision**: Compare the calculated F-statistic with the critical value:\n",
    "   - If $F > F_{\\text{critical}}$, reject the null hypothesis.\n",
    "   - If $F \\leq F_{\\text{critical}}$, fail to reject the null hypothesis.\n",
    "6. **Draw Conclusions**: Interpret the results in the context of the research question.\n",
    "\n",
    "**Use Cases:**\n",
    "- Comparing variances across two or more groups.\n",
    "- Assisting in the assumptions of other statistical tests, such as ANOVA, which assumes equal variances among groups.\n",
    "\n",
    "**Considerations:**\n",
    "- The F-Test is sensitive to non-normality; both groups should ideally be normally distributed for reliable results.\n",
    "- It can also be sensitive to outliers, which may affect the estimated variances.\n",
    "\n",
    "In summary, the F-Test is a vital tool in inferential statistics for assessing the equality of variances between two or more populations, aiding in various statistical analyses and modeling. Understanding the F-Test's principles and applications is crucial for accurate data interpretation in research and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29ab40-cbdb-4936-8ec5-74b40797c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Sample data for two groups\n",
    "group1 = [30, 35, 31, 29, 33]\n",
    "group2 = [41, 39, 45, 37, 43]\n",
    "\n",
    "# Calculate the sample variances\n",
    "var1 = np.var(group1, ddof=1)  # Unbiased estimator (N-1)\n",
    "var2 = np.var(group2, ddof=1)\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F_statistic = var1 / var2\n",
    "\n",
    "# Determine degrees of freedom\n",
    "n1 = len(group1)\n",
    "n2 = len(group2)\n",
    "df1 = n1 - 1  # Degrees of freedom for group 1\n",
    "df2 = n2 - 1  # Degrees of freedom for group 2\n",
    "\n",
    "# Calculate the p-value using the cumulative distribution function (CDF)\n",
    "p_value = 1 - f.cdf(F_statistic, df1, df2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {F_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Choose a significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The variances of the two groups are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between the variances of the two groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23a25d-c65c-44b8-a4ba-5560f7c92ecc",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 11</b></p>\n",
    "\n",
    "**Exercise:** F-Test\n",
    "\n",
    "1. **Data Collection**: You have conducted an experiment to compare the variability in scores of two different teaching methods. The following scores represent the final exam results (out of 100) for each group:\n",
    "\n",
    "   - **Group 1 (Method A)**:\n",
    "   ```python\n",
    "   group1 = [78, 85, 88, 75, 90]\n",
    "   ```\n",
    "\n",
    "   - **Group 2 (Method B)**:\n",
    "   ```python\n",
    "   group2 = [82, 78, 84, 90, 70]\n",
    "   ```\n",
    "\n",
    "2. **Hypothesize**: Your research question is to determine if there is a significant difference in the variances of the two groups' scores.\n",
    "\n",
    "3. **Perform the F-Test**:\n",
    "   - State the null hypothesis (\\(H_0\\)) and alternative hypothesis (\\(H_a\\)).\n",
    "   - Use the F-Test to test the hypothesis by calculating the F-statistic and p-value.\n",
    "   - Choose a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the results of the F-test and the chosen significance level, conclude whether to reject or fail to reject the null hypothesis.\n",
    "   - What does this imply about the variability in scores between the two teaching methods?\n",
    "\n",
    "5. **Bonus Question**: If you were to increase the sample sizes for both groups, how would this impact the power of the test? Discuss the relationship between sample size and the ability to detect differences in variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa586aa-fb19-427a-b7e8-641029c7e5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88946a-b439-42cc-819c-b8b63d820018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9a3f4-b2b0-494a-bf61-e342be104352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba808446-1c30-43b1-b090-1913edd1568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91231480-e283-472e-b134-804b8c2bef22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b4f3e3-ce57-40f6-bb5d-4dd48fbc8dac",
   "metadata": {},
   "source": [
    "### **2.4.5. Chi-Squared Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f575e-942f-4a16-98aa-7886960a703d",
   "metadata": {},
   "source": [
    "The **chi-squared test** is used to determine whether there is a significant association between categorical variables.\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O - E)^2}{E}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $O$: Observed frequencies.\n",
    "- $E$: Expected frequencies under the null hypothesis.\n",
    "\n",
    "**Types of Chi-Squared Tests:**\n",
    "1. **Goodness-of-Fit Test**: Determines if a sample matches an expected distribution.\n",
    "2. **Test for Independence**: Determines if two categorical variables are independent.\n",
    "\n",
    "**Example: Test for Independence**\n",
    "Given a contingency table:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "O_{11} & O_{12} \\\\\n",
    "O_{21} & O_{22}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The expected frequencies are computed as:\n",
    "$$\n",
    "E_{ij} = \\frac{\\text{Row Total} \\times \\text{Column Total}}{\\text{Grand Total}}\n",
    "$$\n",
    "\n",
    "**Interpretation:**\n",
    "- Small p-value ($p < 0.05$): Reject the null hypothesis; the variables are associated.\n",
    "- Large p-value ($p \\geq 0.05$): Fail to reject the null hypothesis; no significant association.\n",
    "\n",
    "**Use Cases:**\n",
    "- Analyzing survey data (e.g., preference vs. demographics).\n",
    "- Testing independence in contingency tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb05c7-fb07-4c51-a4ba-c8d917081a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Example: Chi-Squared Test\n",
    "# Contingency table (e.g., observed frequencies of categories)\n",
    "data = [[50, 30], [20, 40]]  # Rows: Categories, Columns: Groups\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "print(f\"Chi-Squared Statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies:\\n{expected}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The variables are not independent.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The variables are independent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88fd3b-a5dc-4bbe-bac4-12dc85e4b346",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 12</b></p>\n",
    "\n",
    "**Exercise:** Chi-Squared Test for Independence\n",
    "\n",
    "1. **Data Collection**: You conducted a survey to analyze the relationship between pet ownership (Dog, Cat) and gender (Male, Female). The observed frequencies from the survey are as follows:\n",
    "\n",
    "   |            | Male | Female |\n",
    "   |------------|------|--------|\n",
    "   | Dog        | 30   | 10     |\n",
    "   | Cat        | 20   | 40     |\n",
    "\n",
    "   Represent this data in a contingency table:\n",
    "\n",
    "   ```python\n",
    "   data = [[30, 10], [20, 40]]\n",
    "   ```\n",
    "\n",
    "2. **Hypothesize**: Your research question is to determine if there is a significant association between pet ownership and gender.\n",
    "\n",
    "3. **Perform the Chi-Squared Test for Independence**:\n",
    "   - State the null hypothesis ($H_0$) and alternative hypothesis ($H_a$).\n",
    "   - Use the Chi-Squared test to evaluate the hypothesis by calculating the Chi-Squared statistic and p-value.\n",
    "   - Choose a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the results of the Chi-Squared test and the chosen significance level, conclude whether to reject or fail to reject the null hypothesis.\n",
    "   - What does this imply about the association between pet ownership and gender?\n",
    "\n",
    "5. **Bonus Question**: If you were to collect more data and the sample sizes increased significantly, how might this affect your Chi-Squared test results? Discuss the implications of sample size on the power of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1e6ba-1325-4cb0-a6e6-0a05699bd9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a00b03-caee-43c2-8401-ce31e05282a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85491b-7b8e-40c5-9af0-c42f85dee203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69112187-0a22-4169-9355-f776961dd7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3554950-39d0-4f1d-b56f-12cf5f166879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3cfbec4-38b0-4f34-bbce-51c38113d9d4",
   "metadata": {},
   "source": [
    "## **2.5. Analysis of Variance (ANOVA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a795e-5ca2-4068-bc6c-ba9936667bd1",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means of three or more samples (groups) to understand if at least one sample mean is significantly different from the others. It tests the hypothesis that the means of different groups are equal under the assumption that the samples are drawn from normally distributed populations with equal variances.\n",
    "\n",
    "ANOVA decomposes the observed variance in a particular variable into components attributable to different sources of variation. This helps in understanding whether the variation between groups is significant compared to the variation within groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841058a2-926c-4bab-8cd4-49f553640358",
   "metadata": {},
   "source": [
    "### **2.5.1. One-Factor ANOVA (One-Way ANOVA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b1721-3136-47e5-ad76-58d6e718df74",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "One-Factor ANOVA, also known as One-Way ANOVA, is used when comparing the means of more than two groups based on one independent variable (factor). It helps determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups.\n",
    "\n",
    "**Hypotheses:**\n",
    "\n",
    "- **Null Hypothesis ($H_0$)**: All group means are equal.\n",
    "  $$\n",
    "  H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_k\n",
    "  $$\n",
    "- **Alternative Hypothesis ($H_a$)**: At least one group mean is different.\n",
    "  $$\n",
    "  H_a: \\text{At least one } \\mu_i \\text{ is different}\n",
    "  $$\n",
    "\n",
    "**Test Statistic:**\n",
    "\n",
    "ANOVA uses the F-statistic to determine the significance.\n",
    "\n",
    "The F-statistic is calculated as:\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}} = \\frac{\\text{Mean Square Between (MSB)}}{\\text{Mean Square Within (MSW)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **Between-group variance (MSB)**: Measures variation due to the interaction between the samples.\n",
    "- **Within-group variance (MSW)**: Measures variation within each sample.\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "1. Independence of observations.\n",
    "2. Normally distributed populations.\n",
    "3. Homogeneity of variances (equal variances among groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ffaf0-ee61-4a83-b314-bf333256985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for three groups\n",
    "group1 = [22, 23, 27, 30, 25]\n",
    "group2 = [18, 20, 16, 21, 19]\n",
    "group3 = [28, 32, 35, 30, 31]\n",
    "\n",
    "# Perform One-Way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: At least one group mean is significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference between group means.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622a71a-6bcd-41f9-925e-12d34cde5396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb771be6-686b-45cb-813e-575a002739e9",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 13</b></p>\n",
    "\n",
    "**Exercise:** One-Way ANOVA\n",
    "\n",
    "1. **Data Collection**: An educator wants to know if three different teaching methods have different effects on student performance. The test scores (out of 100) for students using each method are as follows:\n",
    "\n",
    "   - **Method A**:\n",
    "     ```python\n",
    "     method_A = [85, 88, 90, 87, 86]\n",
    "     ```\n",
    "   - **Method B**:\n",
    "     ```python\n",
    "     method_B = [78, 82, 80, 76, 79]\n",
    "     ```\n",
    "   - **Method C**:\n",
    "     ```python\n",
    "     method_C = [92, 95, 93, 91, 94]\n",
    "     ```\n",
    "\n",
    "2. **Hypothesize**:\n",
    "   - State the null hypothesis ($H_0$) and alternative hypothesis ($H_a$).\n",
    "\n",
    "3. **Perform One-Way ANOVA**:\n",
    "   - Use Python to perform the ANOVA test.\n",
    "   - Calculate the F-statistic and p-value.\n",
    "   - Use a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the ANOVA results, determine whether to reject or fail to reject the null hypothesis.\n",
    "   - What does this indicate about the effectiveness of the different teaching methods?\n",
    "\n",
    "5. **Post-Hoc Analysis (Bonus)**:\n",
    "   - If significant differences are found, perform a post-hoc test (e.g., Tukey's HSD) to determine which groups differ from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6821d97-7acf-4623-83b4-8a520f6f94b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f73d78-1453-4776-bd65-1faf098eda21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5044c72-bae5-41ee-ba18-1c18ff7dea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb3ec9-1434-4c72-a217-9327f62aaa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9a39f-4e84-4527-95b1-e3f884a9ed2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f75df87-9cdf-4d5c-b4ed-4e906e26fee1",
   "metadata": {},
   "source": [
    "### **2.5.2. Multiple Factors (Two-Way ANOVA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdfa8c-dae6-4a6a-8611-ffd3bd2bd832",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "Two-Way ANOVA is used when analyzing the effect of two independent variables (factors) on a dependent variable. It also helps in understanding if there is an interaction effect between the two factors.\n",
    "\n",
    "**Hypotheses:**\n",
    "\n",
    "1. **Main Effects**:\n",
    "   - For Factor A:\n",
    "     - $H_0$: No effect of Factor A on the dependent variable.\n",
    "     - $H_a$: Significant effect of Factor A.\n",
    "   - For Factor B:\n",
    "     - $H_0$: No effect of Factor B on the dependent variable.\n",
    "     - $H_a$: Significant effect of Factor B.\n",
    "2. **Interaction Effect**:\n",
    "   - $H_0$: No interaction between Factor A and Factor B.\n",
    "   - $H_a$: Significant interaction between Factor A and Factor B.\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "1. Independence of observations.\n",
    "2. Normally distributed populations.\n",
    "3. Homogeneity of variances.\n",
    "4. The groups are defined by both factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae189b-e5f9-4245-84a6-4c95004ccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create sample data\n",
    "data = {\n",
    "    'Score': [85, 88, 90, 87, 86, 78, 82, 80, 76, 79, 92, 95, 93, 91, 94],\n",
    "    'Method': ['A']*5 + ['B']*5 + ['C']*5,\n",
    "    'Gender': ['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform Two-Way ANOVA\n",
    "model = ols('Score ~ C(Method) + C(Gender) + C(Method):C(Gender)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0a023-8892-440e-ad5a-fd89c07ae189",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "\n",
    "- **Sum Sq**: Sum of squares attributable to each source.\n",
    "- **df**: Degrees of freedom.\n",
    "- **F**: F-statistic.\n",
    "- **PR(>F)**: P-value.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- `C(Method)`: Categorical variable 'Method'.\n",
    "- `C(Gender)`: Categorical variable 'Gender'.\n",
    "- `C(Method):C(Gender)`: Interaction between Method and Gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ffae78-1533-4c06-97b7-10b89c2e61f9",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 14</b></p>\n",
    "\n",
    "**Exercise:** Two-Way ANOVA\n",
    "\n",
    "1. **Data Collection**: A researcher is studying the effect of diet and exercise on weight loss. Participants are split into groups based on diet type (Diet 1, Diet 2) and exercise level (Low, High). The weight loss (in kg) for each group is recorded:\n",
    "\n",
    "   | Diet | Exercise Level | Weight Loss (kg) |\n",
    "   |------|----------------|------------------|\n",
    "   | 1    | Low            | [2, 3, 1.5, 2.5] |\n",
    "   | 1    | High           | [4, 4.5, 5, 3.5] |\n",
    "   | 2    | Low            | [1, 2, 1.5, 1.8] |\n",
    "   | 2    | High           | [3, 3.5, 4, 2.8] |\n",
    "\n",
    "2. **Hypothesize**:\n",
    "   - State the null and alternative hypotheses for both main effects and interaction effect.\n",
    "\n",
    "3. **Perform Two-Way ANOVA**:\n",
    "   - Organize the data into a pandas DataFrame.\n",
    "   - Use Python to perform the Two-Way ANOVA.\n",
    "   - Use a significance level of 0.05.\n",
    "\n",
    "4. **Interpret the Results**:\n",
    "   - Based on the ANOVA table, determine the significance of diet, exercise level, and their interaction.\n",
    "   - What does this indicate about the effects on weight loss?\n",
    "\n",
    "5. **Conclusions**:\n",
    "   - Summarize your findings and suggest practical implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd9cd6-b7f2-434a-ae3f-58ff30897c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3469bdc-61cb-4935-b504-1d86458911c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385c23a-6d22-4072-981f-b219ffd83957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446075a-8602-4832-b6f5-c1ea4d3ec561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c56a7-3de8-400b-904d-8d4a864ac055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
