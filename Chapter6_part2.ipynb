{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dd40f5c-6a0f-4b30-a372-097bc68358ff",
   "metadata": {},
   "source": [
    "# **Chapter 6. Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734b641-d63f-454a-8587-1fe33cb8fed3",
   "metadata": {},
   "source": [
    "## **6.3. Regression Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13623401-b690-4dd4-b214-79c184e461dc",
   "metadata": {},
   "source": [
    "In the following sections, will we evaluate different regression models to predict the solubility of chemical compounds:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832fa18-ad09-4586-97a8-cb7565ee9ba9",
   "metadata": {},
   "source": [
    "***a. Import required libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f43f8-cd78-4487-b9e6-7ee6837fb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42e10d-ab04-4db6-aa6e-e4e41b591e6f",
   "metadata": {},
   "source": [
    "***b. Load dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b49fa-9157-412f-9427-a18216bc82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lipophilicity dataset\n",
    "data_file_path = './datasets/Solubility.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83555176-e9c3-44f1-bbf6-6a75115e459e",
   "metadata": {},
   "source": [
    "***c. Get the input and output columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd73835-01b5-4630-8e44-2434b6b9c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['AMW', 'num_rings', 'fraction_CSP3', 'num_hba', 'num_hbd', 'num_het_atoms', 'logP', 'TPSA']].to_numpy()\n",
    "y = df['solubility'].to_numpy()\n",
    "print(f'Shape of inputs: {x.shape}')\n",
    "print(f'Shape of output: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eab20f-b0f6-4111-8d50-f870edeacd29",
   "metadata": {},
   "source": [
    "***d. Data preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba66479-ac15-46cf-ac08-98f69f173b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Define input and output scalers\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the data\n",
    "x_scaled = input_scaler.fit_transform(x)\n",
    "y_scaled = output_scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(x_scaled, y_scaled, test_size=0.3, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b5591-248b-4378-96d3-f4f76fa5e133",
   "metadata": {},
   "source": [
    "***e. Model training and evaluation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079534f5-e68a-4462-907e-9d99de7f07f5",
   "metadata": {},
   "source": [
    "### **6.3.1. Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37550f-f07a-4254-aae4-8306e27345b1",
   "metadata": {},
   "source": [
    "Linear regression is a fundamental approach that models the linear relationship between a dependent variable and one or more independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bd1e9-c020-40af-8f66-44bce00ed0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67ad40-dba5-4051-849e-bd2238aa36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for evaluating the model\n",
    "def evaluate_regression_model(model, x_test_scaled, y_test_scaled):\n",
    "    # Predict on the test set\n",
    "    y_pred_scaled = model.predict(x_test_scaled)\n",
    "    \n",
    "    # Transform predictions back to original scale\n",
    "    y_pred = output_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    # Transform the test set back to original scale\n",
    "    y_test = output_scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print regression metrics\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', edgecolor='k', alpha=0.7, s=40)\n",
    "    plt.plot(y_test, y_test, color='red', linewidth=2)  # Ideal line for perfect predictions\n",
    "    plt.xlabel('Actual Solubility')\n",
    "    plt.ylabel('Predicted Solubility')\n",
    "    plt.title('Predictions vs Actual')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608cd8f-7374-4e0a-bb05-18ba45a6463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d8a75-f114-43a4-b19c-8018bf92f066",
   "metadata": {},
   "source": [
    "After training, we can make predictions with this model, for examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1656f-4e2d-446a-b1d7-972023d6c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([40.065, 0, 0.333333, 0, 0, 0, 0.63950, 0.00])\n",
    "\n",
    "# Scale features\n",
    "features_scaled = input_scaler.transform(features.reshape(1, -1))\n",
    "\n",
    "# Make prediction\n",
    "output_scaled = model.predict(features_scaled)\n",
    "\n",
    "# Transform predictions back to original scale\n",
    "output = output_scaler.inverse_transform(output_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Print out the prediction\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98bd324-2ec6-41bc-b367-734494ad86ae",
   "metadata": {},
   "source": [
    "### **6.3.2. Ridge Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359bf9da-f1ce-4c36-a4f7-1074dcf87ded",
   "metadata": {},
   "source": [
    "Ridge regression extends linear regression by adding a regularization term, which helps in reducing model complexity and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00f9ed-b598-4e26-885e-ff6803f46ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize the Ridge Regression model\n",
    "# You can adjust the alpha parameter to control the amount of regularization\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f6f0a-6ec0-4590-aa12-1d4243670b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f20b4-f808-4261-a747-b1b5c0726741",
   "metadata": {},
   "source": [
    "### **6.3.3. Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b754644-0d7e-46b5-9878-344d257924fb",
   "metadata": {},
   "source": [
    "Lasso regression, similar to ridge regression, adds a regularization term but in a way that can completely eliminate the weights of some features, thus performing feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48873af4-e584-4bb9-a125-ad43b2774f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize the Lasso Regression model\n",
    "# You can adjust the alpha parameter to control the amount of regularization\n",
    "model = Lasso(alpha=0.001)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cd549-a742-426b-b1da-323312d6ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c566a-d17b-4f17-9502-209087a6a9b1",
   "metadata": {},
   "source": [
    "### **6.3.4. Elastic Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261764c2-ad6e-4edd-9373-f47908d427d6",
   "metadata": {},
   "source": [
    "Elastic net combines features of both ridge and lasso regression, using a mix of both L1 and L2 regularization to improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8d9ff-2187-443e-a8b3-8db220075411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "# You can adjust the alpha and l1_ratio parameters to control the amount of regularization\n",
    "# alpha controls the overall strength, while l1_ratio controls the balance between L1 and L2 regularization\n",
    "model = ElasticNet(alpha=0.001, l1_ratio=0.5)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3f1ef-357f-46fe-812c-64df75902d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff92afd-67cf-44b9-937e-c07be59b77d5",
   "metadata": {},
   "source": [
    "### **6.3.5. K-Nearest Neighbors Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2f92f-b291-4438-9131-b2ea3c12f583",
   "metadata": {},
   "source": [
    "KNN regression predicts the output based on the K nearest neighbors in the feature space, averaging their values to determine the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06870b3d-f5ed-4acb-9558-0dc817357d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initialize the KNN regression model\n",
    "# You can adjust the number of neighbors (n_neighbors)\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c8147-1446-4458-88c2-939d559aadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa53c3-8de5-4ef1-a502-66d03fc578c3",
   "metadata": {},
   "source": [
    "### **6.3.6. Decision Tree Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e779a-6df2-44c5-b8aa-1d08ed2cd44c",
   "metadata": {},
   "source": [
    "Decision tree regression models make predictions by splitting data into subsets based on feature values, building a tree-like model of decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5dbd64-b404-4531-8fe2-a7f3f181202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the Decision Tree Regression model\n",
    "# You can adjust various parameters like max_depth, min_samples_split, etc.\n",
    "model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7219b3e-a493-4f4e-9548-2c5861f74d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6042b90-0fee-4371-abf9-21aedcc8c194",
   "metadata": {},
   "source": [
    "### **6.3.7. Random Forest Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3691b89-594a-4a20-bb8e-96a9c0689ec1",
   "metadata": {},
   "source": [
    "Random forest regression improves upon decision tree regression by creating an ensemble of decision trees and averaging their predictions to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19efb4-ef7a-4635-aef1-4d763fbad589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regression model\n",
    "# You can adjust parameters like n_estimators (number of trees), max_depth, etc.\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537f183-2711-430b-85ef-9a4a6fd732ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1779a-3e44-4b50-9823-63a6ed426f11",
   "metadata": {},
   "source": [
    "### **6.3.8. Gaussian Process Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717dcaf-9400-4f69-b177-9c0fc6809d2c",
   "metadata": {},
   "source": [
    "Gaussian process regression is a probabilistic model that uses kernel functions to make predictions, providing not only estimations but also uncertainty measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc7d99-a183-42ea-a4f4-8859307c13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "# Initialize the Gaussian Process Regressor model\n",
    "# You can adjust the kernel and other parameters as needed\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "model = GaussianProcessRegressor(kernel=kernel, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7781c-5180-468b-bc7f-849b6e44d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbc0a0-7231-4f50-8be9-1257034b19b6",
   "metadata": {},
   "source": [
    "### **6.3.9. Support Vector Machine (SVM) Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9b5bc-0919-46d7-b9cd-8a54943eb3e0",
   "metadata": {},
   "source": [
    "SVM regression, or Support Vector Regression (SVR), uses the SVM technique to model complex relationships between features and target variables, including both linear and non-linear interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae15a87-ab7b-4530-b3a6-81a8c6def4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize the SVM Regression model with a Gaussian (RBF) kernel\n",
    "# You can adjust parameters like C (regularization parameter) and gamma (kernel coefficient)\n",
    "model = SVR(kernel='rbf', C=1.0, gamma='scale', epsilon=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040d7fb-1333-4d84-8954-7fed8ed8c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_regression_model(model, x_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc6cdb-7c0e-4c89-bedd-89b35d2dd428",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 1</b></p>\n",
    "\n",
    "1. **Load Data:** Load the lipophilicity dataset from the file `Lipophilicity.csv`. The output column is `lipophilicity`, the other 512 columns are the atom-pairs fingerprint of molecules, which is used for the prediction of lipophilicity. \n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "   - Reduce the number of inputs using method(s) of your choice, the number of reduced input columns should not be greater than 32.\n",
    "   - Split the data into train and test sets (70:30)\n",
    "\n",
    "4. **Model Training and Evaluation:** Train different ML models and evaluate their performance.\n",
    "\n",
    "5. **Analysis:** Analyze the results, choose the best model based on their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6f0bf-00da-4879-973b-357a4ecd9c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce97c1-d2f5-44b7-beba-0126e56bf281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ce43e-f0be-48d8-8191-5e4131219356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd08ec-4beb-46cb-b7df-c7b48e9b23af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8720901d-5baf-4083-8b81-adff0e74b411",
   "metadata": {},
   "source": [
    "## **6.4. Classification Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0b8d9-6534-42fc-be2f-d683d4ce133e",
   "metadata": {},
   "source": [
    "In the following sections, will we evaluate different classification models to predict whether a compound can penetrate blood-brain barrier:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2266ac-10b1-4bd6-84d1-00b0586d60a3",
   "metadata": {},
   "source": [
    "***a. Import required libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806adf5a-3f09-4f05-b36a-09db35a0ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152cbbda-9171-4b75-a2b2-163c6e08e076",
   "metadata": {},
   "source": [
    "***b. Load dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91bf84-c7d9-4f61-a37b-3ce9576dca36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the lipophilicity dataset\n",
    "data_file_path = './datasets/BBBP.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715e179-0e0a-43ee-a125-56a48b948fe5",
   "metadata": {},
   "source": [
    "***c. Get the input and output columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3741ada-8e1d-4e7e-9115-1d8137e80d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('p_np', axis=1).to_numpy()\n",
    "y = df['p_np'].to_numpy()\n",
    "print(f'Shape of inputs: {x.shape}')\n",
    "print(f'Shape of output: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af50b7f-5828-4411-9f5e-82481b02a434",
   "metadata": {},
   "source": [
    "***d. Data preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680855f-2844-4679-96e0-25ea00d1b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Reduce number of inputs with variance threshold and PCA\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "x_reduced = selector.fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=32)  # Reduce to 32 dimensions\n",
    "x_reduced = pca.fit_transform(x_reduced)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_reduced, y, test_size=0.3, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d3184-d767-4702-a66a-4df02bda3942",
   "metadata": {},
   "source": [
    "***e. Model training and evaluation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366afcd-18d1-4a7e-a029-b5cfe360f6a8",
   "metadata": {},
   "source": [
    "### **6.4.1. Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efccf6-c316-4a80-86ca-e148b5822947",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although there are extensions to handle multi-class problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f72285-0a92-4545-8916-0149a4cb8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "# You can adjust the 'C' parameter to control regularization strength\n",
    "model = LogisticRegression(C=1.0, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f784d-21a0-47df-9037-95d549329265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for evaluating the model\n",
    "def evaluate_classification_model(model, x_test, y_test):\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:, 1]  # Probability estimates for the positive class\n",
    "    \n",
    "    # Evaluate the model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Print classification metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (AUC = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4069a72-ee6d-4c89-a406-03d702cfed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abaa1d6-71d5-4aa6-a4fc-1d2a999528eb",
   "metadata": {},
   "source": [
    "### **6.4.2. Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb824b-1f2a-4794-9792-7f1fe015dff4",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong independence assumptions between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f05fa1-172b-401a-b078-9a4cb3a2f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a9f77-6659-491b-abe5-760ff8ecdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880c288-38a6-40a1-9b90-029321130e5a",
   "metadata": {},
   "source": [
    "### **6.4.3. K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973c2f5-7064-4084-822e-1b0cdbf5307e",
   "metadata": {},
   "source": [
    "KNN classification predicts the class of a data point based on the majority class among its k nearest neighbors. It's a simple, distance-based algorithm often used for its ease of interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13007e81-6016-44f4-92fa-b30576749f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "# You can adjust the number of neighbors (n_neighbors)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a71e4-7453-47f4-a4a0-e5b5e1272806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b5548-346d-4e2e-9007-5f51a3af64c9",
   "metadata": {},
   "source": [
    "### **6.4.4. Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2275c8-0ac9-4ce9-bdf6-0a9c835462a2",
   "metadata": {},
   "source": [
    "Decision tree classifiers make decisions by splitting data based on feature values, creating a tree-like model of decisions. They are intuitive and easy to interpret but can be prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16632320-8ebc-48b6-87c9-db7ae517deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "# You can adjust parameters like max_depth, min_samples_split, etc.\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff374c-b5f5-486c-b570-2f809abd25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af10b0-0b41-407e-9e43-a5c623ac33a0",
   "metadata": {},
   "source": [
    "### **6.4.5. Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57af066-6624-4091-840e-32d095bf478f",
   "metadata": {},
   "source": [
    "Random forest classifiers improve upon decision trees by creating an ensemble of decision trees and aggregating their predictions to reduce overfitting and improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee5652-f1e4-49ef-aac1-1a28c0ca0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "# You can adjust parameters like n_estimators (number of trees), max_depth, etc.\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376dbd1-88d9-4182-9c9d-d1beadaef312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ef9ea-e983-42a7-943b-0bdf04fd220b",
   "metadata": {},
   "source": [
    "### **6.4.6. Gaussian Process Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e1d01-b36e-4130-b6e1-076bdae63302",
   "metadata": {},
   "source": [
    "Gaussian Process classifiers extend Gaussian processes to classification tasks, using kernel functions and Bayesian inference to predict categorical outcomes, often with uncertainty estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c93fa-9390-4b1a-826c-9cc1b7d5d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Initialize the Gaussian Process Classifier\n",
    "# The choice of kernel can be important; RBF is a common choice\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "model = GaussianProcessClassifier(kernel=kernel, random_state=random_seed)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49b7b7-0ec1-4a1c-8e6f-aa132f4142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642a401-8845-46b1-87dd-5a2a24815dca",
   "metadata": {},
   "source": [
    "### **6.4.7. Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34452a7e-e635-4db2-bc36-799dd2449634",
   "metadata": {},
   "source": [
    "SVM classifiers construct hyperplanes in a multidimensional space to separate different classes with as wide a margin as possible. SVMs are effective in high-dimensional spaces and versatile with various kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcaf7a-fdad-48e4-b662-ad4e8b5f1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM classifier with a Gaussian (RBF) kernel\n",
    "# You can adjust parameters like C (regularization parameter) and gamma (kernel coefficient)\n",
    "random_seed=0\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=random_seed, probability=True)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17d261-7e4c-43bc-bd89-d496e1543a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_classification_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb9fd9-8b8d-4bdf-a5d2-37d004b43ecf",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 2</b></p>\n",
    "\n",
    "1. **Load Data:** Load the breast cancer dataset from the file `BreastCancer.csv`. The output column is `diagnosis`, the other columns are used as inputs. \n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "   - Scale the input and output columns using min-max scaler\n",
    "   - Reduce the number of inputs using method(s) of your choice, the number of reduced input columns should not be greater than 16.\n",
    "   - Split the data into train and test sets (70:30)\n",
    "\n",
    "4. **Model Training and Evaluation:** Train different ML models and evaluate their performance.\n",
    "\n",
    "5. **Analysis:** Analyze the results, choose the best model based on their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4060269-956b-43fa-9737-abd41c72437e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
