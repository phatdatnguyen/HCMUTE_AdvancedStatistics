{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347c6734-d6de-4baf-a2df-c7e0bf3706bc",
   "metadata": {},
   "source": [
    "# **Chapter 7. Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f73834-f01c-493c-889d-a2fd2c33b486",
   "metadata": {},
   "source": [
    "## **7.2. Multilayer Perceptron (MLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a10b11-d955-4bb9-a5d3-00cb3261fd43",
   "metadata": {},
   "source": [
    "In this section, we will explore the structure of a MLP, and use MLP network to solve more complex regression and classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda93b0-e588-403a-92f1-e8c70112ffd4",
   "metadata": {},
   "source": [
    "### **7.2.1. Structure of MLP Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc896de3-c6d9-4d0e-9c22-367f75773d92",
   "metadata": {},
   "source": [
    "The structure of a MLP network can be described as follow:\n",
    "\n",
    "![MLP structure](images/MLP_structure.png)\n",
    "\n",
    "**Key points to remember about MLP network**\n",
    "\n",
    "- MLP can solve comlex problems with non-linearity, which a single perceptron can not.\n",
    "- MLP contains 1 or multiple hidden layers and 1 output layer. Each layer has a defined number of perceptrons (neurons) in it.\n",
    "- Each neurons contains the weights (w) for each of its inputs, and a bias (b).\n",
    "- The output of a neuron is calculated using the following equation:\n",
    "\n",
    " $$\\text{output} = f(\\sum_{i}(w_i \\times x_i) + b)$$\n",
    "\n",
    "- The output of a neuron should be passed through an activation function. Activation function has many purposes in neural network, such as mapping the values to a new desired range, and introducing non-linearity to the network.\n",
    "- Some commonly used activation function in ANN are:\n",
    " \n",
    "![Activation functions](images/activation_functions.png)\n",
    "\n",
    "- The input and output values of the network should be scaled to small range for gradient descent to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3cf986-cf32-4b31-a1b6-e3c2db750d2f",
   "metadata": {},
   "source": [
    "### **7.2.2. How MLP Network Works**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0a34a-1253-4192-81b3-cb3278c10660",
   "metadata": {},
   "source": [
    "The workflow of an MLP network is similar to a single-perceptron network, which includes the following steps:\n",
    "- **Step 1.** Initialize parameters\n",
    "- **Step 2.** Forward pass\n",
    "- **Step 3.** Calculate the value of the loss function\n",
    "- **Step 4.** Backward pass\n",
    "- **Step 5.** Update parameters.\n",
    "- Return to **Step 2**, repeat after a number of iterations (epochs) or until the loss function is low enough.\n",
    "\n",
    "During the backward pass, the change chain rule is applied to calculate the gradients through activation functions. For example:\n",
    "\n",
    "![Backpropagation - Activation functions](images/backpropagation_activation_function.png)\n",
    "\n",
    "Because the gradient flows through activation function, **the first derivative of the activation function must exist** in order for backpropagation to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506b2bb-cf9a-4016-bc9e-44bdd5f2fa58",
   "metadata": {},
   "source": [
    "### **7.2.3. MLP for Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2bb69-be04-4903-a171-284b5a7249b7",
   "metadata": {},
   "source": [
    "#### ***7.2.3.1. MLP network with 1 input, 1 hidden layer containing 5 neurons, 1 output***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f996a6-ca18-4bef-b62a-3f892c214b8e",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to perform regression for non-linear function y=f(x)\n",
    "\n",
    "*Network structure:*\n",
    "\n",
    "![MLP network](images/MLP_1_5_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbea045-819b-4c0e-a218-315761e87eae",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78477dac-af62-4789-ba39-513f046e527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696c039-cf02-4cca-9fbc-0c6a9f627551",
   "metadata": {},
   "source": [
    "**a. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddb142-1302-4f1f-a451-c9d9af58c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data points\n",
    "x = np.linspace(0, 10, 11)\n",
    "y = x*x*x - 10*x*x + 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0ce34-3a2a-4315-8616-5e5a4f74c5d8",
   "metadata": {},
   "source": [
    "**b. Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f65e3-fee4-458a-b2a9-d23f38986517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output scalers\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the data to the range from 0 to 1\n",
    "x_scaled = input_scaler.fit_transform(x.reshape(-1, 1)).reshape(-1)\n",
    "y_scaled = output_scaler.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Convert to tensor\n",
    "x_scaled = torch.tensor(x_scaled, dtype=torch.float)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db446b88-d307-44e9-97a8-7c606ddd42bf",
   "metadata": {},
   "source": [
    "**c. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b786848-646c-4554-af55-95746677c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression class\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.hidden = nn.Linear(1, 5)  # 1 input and 5 hidden\n",
    "        self.output = nn.Linear(5, 1)  # 5 hidden and 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return self.output(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RegressionModel()\n",
    "\n",
    "# View the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3eee20-12d3-461a-95b0-9697c5c93635",
   "metadata": {},
   "source": [
    "**d. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d0a28-6a02-4587-ad07-0cf8b9094bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Forward pass\n",
    "    outputs = model(x.unsqueeze(1))\n",
    "    loss = criterion(outputs, y.unsqueeze(1))\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Create lists of losses for visualization\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76a5a-8841-4d85-bd0f-48f57e87008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 5000\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_scaled, y_scaled)\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    losses.append(train_loss)\n",
    "        \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d13025-5520-4ba7-86ea-ca957a429eb0",
   "metadata": {},
   "source": [
    "**e. Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b276bed-3e01-43d6-8dac-9a56f2c983f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis limits\n",
    "x_min = math.floor(min(x))\n",
    "x_max = math.ceil(max(x))\n",
    "y_min = math.floor(min(y))\n",
    "y_max = math.ceil(max(y))\n",
    "\n",
    "# Create the plot\n",
    "x_values = np.linspace(x_min, x_max, num=101)\n",
    "x_values_scaled = input_scaler.transform(x_values.reshape(-1, 1)).reshape(-1)\n",
    "y_values_scaled = model(torch.tensor(x_values_scaled).float().unsqueeze(1))\n",
    "y_values_scaled = y_values_scaled.detach().numpy()\n",
    "y_values = output_scaler.inverse_transform(y_values_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x, y, color='red')\n",
    "plt.plot(x_values, y_values)\n",
    "plt.show()\n",
    "\n",
    "# Visualize MSE loss values over time\n",
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e290937-e98f-4b6e-ba45-5a96828db22a",
   "metadata": {},
   "source": [
    "**f. Make prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dac80-5847-4e4a-8f91-d70f3576eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for prediction\n",
    "x_pred = 5\n",
    "\n",
    "# Scale input to range 0 to 1\n",
    "x_pred_scaled = input_scaler.transform([[x_pred]])\n",
    "\n",
    "# Convert to tensor\n",
    "x_pred_scaled = torch.tensor(x_pred_scaled).float()\n",
    "\n",
    "# Run model forward\n",
    "y_pred_scaled = model(x_pred_scaled)\n",
    "\n",
    "# Convert back to number\n",
    "y_pred_scaled = y_pred_scaled.item()\n",
    "\n",
    "# Scale output back to original range\n",
    "y_pred = output_scaler.inverse_transform([[y_pred_scaled]])[0][0]\n",
    "\n",
    "# Show result\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f30a8e-775d-4fef-af29-0a5337a55015",
   "metadata": {},
   "source": [
    "**g. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c0d9a-5d5c-4d85-bff1-54cc5080cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'MLP1'\n",
    "file_name = f'./{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58fb1f-19ed-4a0c-9e9e-4426a627ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'./{model_name}_5000.ckpt'\n",
    "loaded_model = RegressionModel()\n",
    "loaded_model.load_state_dict(torch.load(file_name, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de251b-eb86-4430-9946-f623b0cc5cee",
   "metadata": {},
   "source": [
    "#### ***7.2.3.2. MLP network with 3 inputs, 2 hidden layers containing 5 neurons each, 2 outputs***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014ca3-4f24-4a59-98ae-42ad6d59b1b1",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to perform regression for non-linear function with multiple inputs and outputs $(y_1, y_2) = f(x_1, x_2, x_3)$\n",
    "\n",
    "*Network structure:*\n",
    "    \n",
    "![MLP network](images/MLP_3_5_5_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bb588-8a5e-4851-ad6d-b3242fa00205",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d94317-f0ef-435d-b5b4-65eb975cb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cafb8-6340-4896-9c1c-9b57cd3c560d",
   "metadata": {},
   "source": [
    "**a. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6952a-f36b-4b6b-a1d6-8484bc878157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data points\n",
    "np.random.seed(42)\n",
    "x1 = np.random.rand(10)\n",
    "x2 = np.random.rand(10)\n",
    "x3 = np.random.rand(10)\n",
    "y1 = x1*x1*x2 - 5*x2*x3 + 5\n",
    "y2 = x3*x1 + 8*x2*x1 - 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193aa56-2f0c-49fc-9014-6250939a888f",
   "metadata": {},
   "source": [
    "**b. Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75876e2-52d9-4c06-b598-5fe1f3cee6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine inputs into 1 array\n",
    "x = np.column_stack((x1, x2, x3))\n",
    "\n",
    "# Combine outputs into 1 array\n",
    "y = np.column_stack((y1, y2))\n",
    "\n",
    "# Define input and output scalers\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale the data to the range from 0 to 1\n",
    "x_scaled = input_scaler.fit_transform(x)\n",
    "y_scaled = output_scaler.fit_transform(y)\n",
    "\n",
    "# Convert to tensor\n",
    "x_scaled = torch.tensor(x_scaled, dtype=torch.float)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0cda0-2e80-4b41-bd41-85d8b9c36de1",
   "metadata": {},
   "source": [
    "**c. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded9fdd-a950-438f-836d-0197ac2b5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression class\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.hidden1 = nn.Linear(3, 5)  # 3 input and 5 hidden\n",
    "        self.hidden2 = nn.Linear(5, 5)  # 5 hidden and 5 hidden\n",
    "        self.output = nn.Linear(5, 2)  # 5 hidden and 2 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return self.output(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RegressionModel()\n",
    "\n",
    "# View the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80c722-cd92-4299-8399-238a86149f52",
   "metadata": {},
   "source": [
    "**d. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a5220-8f1b-4e81-9c19-8c6df6876f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Create lists of losses for visualization\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868fcaf-d8f7-49ef-9a76-fd68849ac4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 5000\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_scaled, y_scaled)\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    losses.append(train_loss)\n",
    "        \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969e222-5458-471c-bde8-0b9dfc12d81f",
   "metadata": {},
   "source": [
    "**e. Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8818f2-4f7d-43e5-b347-42d766d01524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87996f4c-8eb2-4aec-ad38-a68083a87c3a",
   "metadata": {},
   "source": [
    "**f. Make prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1e89d-a332-47e7-b2f3-af140723674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for prediction\n",
    "x_pred = [8, 3, 4]\n",
    "\n",
    "# Scale input to range 0 to 1\n",
    "x_pred_scaled = input_scaler.transform([x_pred])\n",
    "\n",
    "# Convert to tensor\n",
    "x_pred_scaled = torch.tensor(x_pred_scaled).float()\n",
    "\n",
    "# Run model forward\n",
    "y_pred_scaled = model(x_pred_scaled)\n",
    "\n",
    "# Convert back to number\n",
    "y_pred_scaled = y_pred_scaled.detach().numpy()\n",
    "\n",
    "# Scale output back to original range\n",
    "y_pred = output_scaler.inverse_transform(y_pred_scaled)[0]\n",
    "\n",
    "# Show result\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053376e-f719-4114-86ec-3df663ae7b60",
   "metadata": {},
   "source": [
    "**g. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4a034-f7e3-4775-9ff2-819de3d58ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'MLP2'\n",
    "file_name = f'./{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f51c17-ea60-432f-a0bb-f2ba2d777ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'./{model_name}_5000.ckpt'\n",
    "loaded_model = RegressionModel()\n",
    "loaded_model.load_state_dict(torch.load(file_name, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e87b1-533f-4b53-8a9b-7dbafaad3593",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 1</b></p>\n",
    "\n",
    "1. **Load Data:** Load the solubility dataset from the file `Solubility.csv`.\n",
    "\n",
    "2. **Data Preprocessing:** Scale the inputs and outputs with min-max scaler.\n",
    "\n",
    "3. **Model Training and Evaluation:** Train a MLP network with 2 hidden layers, each contains 32 neurons and evaluate its performance in predicting water solubility of molecules.\n",
    "\n",
    "4. **Change Model Parameters:** Try again with different MLP architectures, explorer the effects of number of epochs and learning rate on model performance and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a3ac1-277a-46fe-b358-d51b80a70a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2cbf5-53fb-4360-911a-1fb8f11e0f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b691149-b00c-4c9c-9eff-c9cccbccd32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df9f7a-e3f9-479a-b572-b1ffc6cfc276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a8c25fc-5b4f-4e0a-ad8b-41b42c3ae8b8",
   "metadata": {},
   "source": [
    "### **7.2.4. MLP for Binary Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7706aec-fd73-4e49-a3f6-cf403e470ab9",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to predict whether a molecule can penetrate the blood-brain barrier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b17b12-c2ce-45a2-ac06-56df0adbaba5",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c083fca-0225-4b30-ba5f-4dd7fb364e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2de06a-0a87-45b3-8c4d-00b3865018af",
   "metadata": {},
   "source": [
    "**a. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2ff0b-f16e-4906-a7f9-0b3d863f24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_file_path = './datasets/BBBP.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c824f3-687d-4bd9-a413-855a6f45bcdb",
   "metadata": {},
   "source": [
    "***c. Get the input and output columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43da84-f8af-4c26-a999-e1bb65065f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('p_np', axis=1).to_numpy()\n",
    "y = df['p_np'].to_numpy()\n",
    "print(f'Shape of inputs: {x.shape}')\n",
    "print(f'Shape of output: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96066ec5-f324-4744-be82-2dc8b7c981f9",
   "metadata": {},
   "source": [
    "**d. Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d27db-58a8-4ed0-85f6-26e92d259dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Reduce number of inputs with variance threshold and PCA\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "x_reduced = selector.fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=32)  # Reduce to 32 dimensions\n",
    "x_reduced = pca.fit_transform(x_reduced)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_reduced, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd399341-6d55-4f7b-8666-988c5d701c1f",
   "metadata": {},
   "source": [
    "**e. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c420ff6-b64c-4f40-b7dc-30a607930c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification model class\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, n_inputs, n_layers, n_hiddens, n_outputs):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        self.hiddens.append(nn.Linear(n_inputs, n_hiddens))\n",
    "        for _ in range(1, n_layers):\n",
    "            self.hiddens.append(nn.Linear(n_hiddens, n_hiddens))\n",
    "        self.output = nn.Linear(n_hiddens, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden in self.hiddens:\n",
    "            x = torch.sigmoid(hidden(x))\n",
    "        return self.output(x)\n",
    "\n",
    "# Instantiate the model\n",
    "n_inputs = x_train.shape[1]\n",
    "n_layers = 3\n",
    "n_hiddens = 64\n",
    "n_outputs = 1\n",
    "model = ClassificationModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "\n",
    "# View the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f016b9-d7a6-45e9-a343-efd7c558a0ac",
   "metadata": {},
   "source": [
    "**f. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20183fb4-4674-4626-b877-011aef5ee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.05)\n",
    "\n",
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Define the validation function\n",
    "def validation(x, y):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Create lists of losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201fdb9-942d-4516-9163-7699816968a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 200\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_train, y_train.unsqueeze(1))\n",
    "    val_loss = validation(x_val, y_val.unsqueeze(1))\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be04f7-72f2-4d99-9f57-e62c94e661ee",
   "metadata": {},
   "source": [
    "**g. Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee507f-edcd-431d-ba3c-a0a6e55d3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('BCE loss with logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f968fd0-9d8c-408a-8ad5-55cf6f8f55f1",
   "metadata": {},
   "source": [
    "**h. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb4bdd-ea9c-4991-978e-2cc33547cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward the test set\n",
    "logits = model(x_test)\n",
    "probabilities = torch.sigmoid(logits).detach().cpu().numpy().reshape(-1)\n",
    "y_pred = np.round(probabilities)\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "roc_auc = roc_auc_score(y_test, probabilities)\n",
    "\n",
    "# Display classification metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6169a0-e3fd-401a-b315-32c2b073a5a1",
   "metadata": {},
   "source": [
    "**i. Save and load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b18d90-50c8-4b83-8215-f3246e0fb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'MLP3'\n",
    "file_name = f'./{model_name}_{num_epochs}.ckpt'\n",
    "torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4f5e5-4dcc-4b5c-9629-5cda2a747908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "file_name = f'./{model_name}_200.ckpt'\n",
    "loaded_model = ClassificationModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "loaded_model.load_state_dict(torch.load(file_name, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d19b9c-a469-4fc6-a321-791df2f7f762",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 2</b></p>\n",
    "\n",
    "1. **Load Data:** Load the breast cancer dataset from the file `BreastCancer.csv`.\n",
    "\n",
    "2. **Data Preprocessing:** Scale the inputs and outputs with min-max scaler.\n",
    "\n",
    "3. **Model Training and Evaluation:** Train a MLP network with a structure of your choice and evaluate its performance in predicting breast cancer.\n",
    "\n",
    "4. **Change Model Parameters:** Try again with different MLP architectures, explorer the effects of number of epochs and learning rate on model performance and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e6921-467f-4832-b443-69dd449744cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112c4f3-4d8e-4e4f-a56d-0c8c86179394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a92233-3dae-47ab-9241-8e1c685378b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829426f2-41e2-4a36-b8c7-2c830dc9c4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6acc4e43-77fb-4813-96bc-faf5babd5f3d",
   "metadata": {},
   "source": [
    "### **7.2.5. MLP for Multiclass Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34975b35-b220-4a08-89c1-9e60b6dc9396",
   "metadata": {},
   "source": [
    "In this section, we will build an MLP network to predict the species of iris flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16aba6a-dce7-4d7a-8a2d-996d791bd2a7",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a878f31-170b-4c81-ab61-01e5a3e1971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fc04b-fbd4-4b80-b45e-a81fe417bd5c",
   "metadata": {},
   "source": [
    "**a. Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a331fe-f921-4edf-bf4d-abdda698799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_file_path = './datasets/Wine.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de190f-3d5f-42ec-956f-94d99f465bbc",
   "metadata": {},
   "source": [
    "***c. Get the input and output columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fb402-aac2-428a-8c04-f341eafb0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Wine', axis=1).to_numpy()\n",
    "y = df['Wine'].to_numpy()\n",
    "print(f'Shape of inputs: {x.shape}')\n",
    "print(f'Shape of output: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a74ce3-9003-4939-b247-a6fc8aabfcba",
   "metadata": {},
   "source": [
    "**d. Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2fa0e-2b0b-4c25-9698-3b68b886ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input to the range from 0 to 1\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled = input_scaler.fit_transform(x)\n",
    "\n",
    "# Encode the output with one-hot encoder\n",
    "output_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = output_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_scaled, x_test_scaled, y_train_encoded, y_test_encoded = train_test_split(x_scaled, y_encoded, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "x_train_scaled, x_val_scaled, y_train_encoded, y_val_encoded = train_test_split(x_train_scaled, y_train_encoded, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "x_train_scaled = torch.tensor(x_train_scaled, dtype=torch.float)\n",
    "y_train_encoded = torch.tensor(y_train_encoded, dtype=torch.float)\n",
    "x_val_scaled = torch.tensor(x_val_scaled, dtype=torch.float)\n",
    "y_val_encoded = torch.tensor(y_val_encoded, dtype=torch.float)\n",
    "x_test_scaled = torch.tensor(x_test_scaled, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2957498-afc1-44f8-a4e6-4df2a55bd5a1",
   "metadata": {},
   "source": [
    "**e. Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4a53d-bd0a-4fe3-9ac2-53867c73494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification model class\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, n_inputs, n_layers, n_hiddens, n_outputs):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        self.hiddens.append(nn.Linear(n_inputs, n_hiddens))\n",
    "        for _ in range(1, n_layers):\n",
    "            self.hiddens.append(nn.Linear(n_hiddens, n_hiddens))\n",
    "        self.output = nn.Linear(n_hiddens, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for hidden in self.hiddens:\n",
    "            x = torch.sigmoid(hidden(x))\n",
    "        return self.output(x)\n",
    "\n",
    "# Instantiate the model\n",
    "n_inputs = x_train_scaled.shape[1]\n",
    "n_layers = 3\n",
    "n_hiddens = 64\n",
    "n_outputs = y_train_encoded.shape[1]\n",
    "model = ClassificationModel(n_inputs, n_layers, n_hiddens, n_outputs)\n",
    "\n",
    "# View the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdb31d-fc48-4f7f-8d4b-049ea0e8e3be",
   "metadata": {},
   "source": [
    "**f. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058757f-2256-4265-ae06-07b3b75849be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the train function\n",
    "def train(x, y):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Define the validation function\n",
    "def validation(x, y):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Create lists of losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a7941-ad89-49f8-b2b9-a274bf11875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 500\n",
    "progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = train(x_train_scaled, y_train_encoded)\n",
    "    val_loss = validation(x_val_scaled, y_val_encoded)\n",
    "    \n",
    "    # Add loss to lists for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    # Print progress\n",
    "    progress_bar.set_description(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61feb8-8e66-49ac-8949-cc439ddad948",
   "metadata": {},
   "source": [
    "**g. Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5559-1bd0-423e-89b2-a20a3b7c19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE loss values over time\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cross entropy loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e133d84-83df-4e67-aa36-b38d7117db64",
   "metadata": {},
   "source": [
    "**h. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f906b-5e15-4e8e-aa5f-b57dbd640f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward the test set\n",
    "logits = model(x_test_scaled)\n",
    "probabilities = torch.softmax(logits, dim=1).detach().cpu().numpy()  # Get probabilities\n",
    "y_pred = np.argmax(probabilities, axis=1) # Get predicted class labels\n",
    "y_test = np.argmax(y_test_encoded, axis=1) # Get actual class labels\n",
    "\n",
    "# Evaluate the model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display classification metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d210b-ced0-4fc8-bacd-f038de0d9615",
   "metadata": {},
   "source": [
    "<p style=\"background-color: lightgreen; text-align: center; font-size: 18px; color: red; padding: 5px; border-radius: 10px;\"><b>Exercise 3</b></p>\n",
    "\n",
    "1. **Load Data:** Load the iris flower dataset from the file `IrisFlower.csv`.\n",
    "\n",
    "2. **Data Preprocessing:** Scale the inputs and outputs with min-max scaler.\n",
    "\n",
    "3. **Model Training and Evaluation:** Train a MLP network with a structure of your choice and evaluate its performance in predicting iris flower species.\n",
    "\n",
    "4. **Change Model Parameters:** Try again with different MLP architectures, explorer the effects of number of epochs and learning rate on model performance and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727df51-1156-4fad-9fb4-2bdc9fba2198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66b41b-716d-4f9f-86c7-5f1f49de3370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b4e49-085e-415b-967e-2c1205d6a0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0babb-a868-4d55-960d-7d75467b7647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
